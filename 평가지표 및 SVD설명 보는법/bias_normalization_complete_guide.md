# Bias 모델과 정규화 완벽 이해 가이드

## 🎯 **목표**

초보자도 이해하는 쉬운 설명으로:
- Bias가 뭔지 이해
- 정규화가 왜 필요한지 이해
- 둘이 성능을 어떻게 높이는지 이해

---

## 📚 **Part 1: Bias 모델**

### **1️⃣ Bias의 직관적 이해**

**시나리오: 카페 평가**

```
일반 평점: 평균 3.5점

개인 성향:
- 철수: 항상 높게 평가하는 사람
  철수의 평가 = 일반 평점 + 0.5점
  철수는 평균적으로 4.0점을 준다

- 영희: 항상 낮게 평가하는 사람
  영희의 평가 = 일반 평점 - 0.5점
  영희는 평균적으로 3.0점을 준다

카페 성향:
- 카페 A: 맛있는 카페
  카페 A의 평가 = 일반 평점 + 0.3점
  카페 A는 평균 3.8점을 받는다

- 카페 B: 맛없는 카페
  카페 B의 평가 = 일반 평점 - 0.3점
  카페 B는 평균 3.2점을 받는다
```

**예측:**
```
철수가 카페 A의 평점을 주려면?
예측 = 기본 평점 + 철수의 특성 + 카페 A의 특성
     = 3.5 + 0.5 + 0.3
     = 4.3점

철수는 보통 4.0점을 주고,
카페 A는 보통 3.8점을 받으므로
결합하면 4.3점이 자연스럽다!
```

---

### **2️⃣ 영화 추천에서의 Bias**

**사용자 Bias (User Bias)**

```python
# 각 사용자의 평가 성향
user_bias[사용자1] = 사용자1의_평균_평점 - 전체_평균_평점

예시:
전체 평균 평점 = 3.5점

사용자 1의 평균 = 4.2점
user_bias[1] = 4.2 - 3.5 = +0.7
→ "이 사용자는 높게 평가하는 경향"

사용자 2의 평균 = 2.9점
user_bias[2] = 2.9 - 3.5 = -0.6
→ "이 사용자는 낮게 평가하는 경향"
```

**영화 Bias (Movie Bias)**

```python
# 각 영화의 평가 경향
movie_bias[영화1] = 영화1의_평균_평점 - 전체_평균_평점

예시:
전체 평균 평점 = 3.5점

영화 A의 평균 = 4.5점
movie_bias[A] = 4.5 - 3.5 = +1.0
→ "이 영화는 좋은 영화 (높게 평가됨)"

영화 B의 평균 = 2.0점
movie_bias[B] = 2.0 - 3.5 = -1.5
→ "이 영화는 나쁜 영화 (낮게 평가됨)"
```

---

### **3️⃣ Bias 없는 예측 vs Bias 있는 예측**

**Bias 없음:**
```python
# 순수 협업 필터링
pred = 사용자_벡터 · 영화_벡터
     = 0.8

문제: 이 사용자의 성향(높게 평가)을 무시!
     이 영화의 품질(좋은 영화)을 무시!
```

**Bias 있음:**
```python
# 협업 필터링 + Bias
pred = 사용자_벡터 · 영화_벡터 + user_bias + movie_bias + mean
     = 0.8 + 0.7 + 1.0 + 3.5
     = 6.0 → clip(5.0) = 5.0

개선: 사용자의 성향과 영화의 품질을 반영!
```

---

### **4️⃣ 성능 개선**

```
Bias 없음: RMSE = 1.05
Bias 있음: RMSE = 1.00

개선율: (1.05 - 1.00) / 1.05 = 4.7% 개선 ✅
```

---

## 📊 **Part 2: 정규화 (Normalization)**

### **1️⃣ 정규화의 필요성 - 스케일 문제**

**문제 상황:**

```
모델 A의 예측값:
[1.0, 2.0, 3.0, 4.0, 5.0]
범위: 1 ~ 5 (매우 넓음)
표준편차: 1.41

모델 B의 예측값:
[3.4, 3.5, 3.6, 3.7, 3.8]
범위: 3.4 ~ 3.8 (매우 좁음)
표준편차: 0.14

💥 문제: 스케일이 너무 다름!

가중 평균 (50:50):
= 0.5 × 3.0 + 0.5 × 3.6
= 3.3

모델 B의 결과에만 영향을 받음!
모델 A는 무시됨!
```

---

### **2️⃣ 정규화 방법: Z-점수 (Z-Score)**

**공식:**

```
정규화된_값 = (원래_값 - 평균) / 표준편차
```

**예시:**

```
모델 A의 예측: 3.0
모델 A의 평균: 3.0
모델 A의 표준편차: 1.41

정규화 = (3.0 - 3.0) / 1.41 = 0

모델 B의 예측: 3.6
모델 B의 평균: 3.6
모델 B의 표준편차: 0.14

정규화 = (3.6 - 3.6) / 0.14 = 0

둘 다 0이 되어 공정함!
```

---

### **3️⃣ 정규화 후 가중 평균**

```
정규화 전:
가중 평균 = 0.5 × 3.0 + 0.5 × 3.6 = 3.3
→ 모델 B에 치우침

정규화 후:
정규화된 A = (3.0 - 3.0) / 1.41 = 0
정규화된 B = (3.6 - 3.6) / 0.14 = 0

가중 평균 = 0.5 × 0 + 0.5 × 0 = 0

원래 스케일로 복원:
최종 = 3.5 + 0 × 1.0 = 3.5
→ 완벽한 균형!
```

---

### **4️⃣ 정규화의 효과**

```
정규화 없음: RMSE = 0.95
정규화 있음: RMSE = 0.92

개선율: (0.95 - 0.92) / 0.95 = 3.2% 개선 ✅
```

---

## 🔗 **Part 3: Bias와 정규화의 결합**

### **최종 예측 공식**

```python
def predict(user_id, movie_id):
    # 1단계: 정규화된 협업 필터링
    user_factors = normalize(user_factors)
    movie_factors = normalize(movie_factors)
    
    latent_score = np.dot(user_factors, movie_factors)
    
    # 2단계: 스케일 복원
    scaled_score = latent_score * std_rating
    
    # 3단계: Bias 추가
    user_bias = user_평균 - 전체_평균
    movie_bias = movie_평균 - 전체_평균
    
    pred = scaled_score + user_bias + movie_bias + mean_rating
    
    # 4단계: 범위 제한
    return np.clip(pred, 1, 5)
```

**각 단계별 효과:**

```
1단계 (정규화): RMSE 1.05
2단계 (스케일): RMSE 1.02
3단계 (Bias): RMSE 1.00 ✅
4단계 (클립): RMSE 1.00
```

---

## 💡 **Part 4: 실제 예시**

### **사용자 1이 영화 X의 평점을 줄 때:**

**Step 1: 기본 정보**
```
전체 평균 평점 = 3.5
사용자 1의 평균 = 4.2
영화 X의 평균 = 4.1
```

**Step 2: Bias 계산**
```
user_bias = 4.2 - 3.5 = +0.7
movie_bias = 4.1 - 3.5 = +0.6
```

**Step 3: SVD 협업 필터링 (정규화)**
```
정규화 전 내적 = 2.5
정규화 후 내적 = (2.5 - 평균) / 표준편차 = 0.8
스케일 복원 = 0.8 × 1.2 = 0.96
```

**Step 4: Bias 추가**
```
pred = 0.96 + 0.7 + 0.6 + 3.5
     = 5.76 → clip(5.0)
     = 5.0
```

**결과 해석:**
```
협업 필터링만: 대략 4.5점
+ 사용자의 높은 평가 경향: +0.7
+ 영화의 좋은 평가: +0.6
= 최종 예측: 5.0점 ✅
```

---

## 🎯 **Part 5: 왜 성능이 향상되는가?**

### **Bias의 효과**

```
문제 1: "모든 사용자를 동일하게 취급"
해결책: User Bias로 개인 성향 반영
결과: 오차 감소 ↓

문제 2: "모든 영화를 동일하게 취급"
해결책: Movie Bias로 영화 품질 반영
결과: 오차 감소 ↓

종합 효과: RMSE 1.05 → 1.00 (5% 개선)
```

### **정규화의 효과**

```
문제 1: "모델 간 스케일이 다름"
해결책: Z-점수로 정규화
결과: 공정한 결합 ↓

문제 2: "일부 모델이 다른 모델 무시"
해결책: 정규화로 동등한 가중치
결과: 모든 모델 활용 ↓

종합 효과: RMSE 0.95 → 0.92 (3% 개선)
```

---

## 📊 **Part 6: 시각적 비교**

### **정규화 전 vs 정규화 후**

```
정규화 전:
모델 A: |---|----|----|----|----|  (범위: 1-5)
모델 B: |-----|-----|-----|         (범위: 3.4-3.8)

가중 평균 계산: 모델 B에 치우침 ❌

정규화 후:
모델 A: |-----|-----|----|----|----|  (z-score: -1 ~ +1)
모델 B: |-----|-----|----|----|----|  (z-score: -1 ~ +1)

가중 평균 계산: 공정함 ✅
```

---

## 🚀 **Part 7: 실제 구현**

### **Bias 계산**

```python
# 사용자 Bias
user_bias = {}
global_mean = ratings['rating'].mean()

for user_id in ratings['userId'].unique():
    user_ratings = ratings[ratings['userId'] == user_id]
    user_mean = user_ratings['rating'].mean()
    user_bias[user_id] = user_mean - global_mean
```

### **정규화 (Z-점수)**

```python
# 각 모델의 예측값 정규화
def normalize(predictions, mean, std):
    return (predictions - mean) / (std + 1e-8)

# 사용 예
normalized = normalize(pred, model_mean, model_std)
```

### **최종 예측**

```python
def predict(user_id, movie_id):
    # CF
    cf_pred = cf_model(user_id, movie_id)
    
    # CB
    cb_pred = cb_model(user_id, movie_id)
    
    # 정규화
    norm_cf = (cf_pred - cf_mean) / cf_std
    norm_cb = (cb_pred - cb_mean) / cb_std
    
    # 가중 평균
    hybrid = 0.5 * norm_cf + 0.5 * norm_cb
    
    # 스케일 복원
    final = 3.5 + hybrid * 1.0
    
    # Bias 추가
    final += user_bias[user_id] + movie_bias[movie_id]
    
    # 범위 제한
    return np.clip(final, 1, 5)
```

---

## ✅ **체크리스트**

```
이해해야 할 것:

Bias 모델:
☐ User Bias의 의미 (사용자 성향)
☐ Movie Bias의 의미 (영화 품질)
☐ 예측 공식에서의 역할
☐ 성능 개선 효과 (4-5%)

정규화:
☐ 스케일 문제 이해
☐ Z-점수 공식
☐ 정규화 전후 비교
☐ 성능 개선 효과 (3%)

결합:
☐ Bias + 정규화 공식
☐ 각 단계의 역할
☐ 최종 예측 과정
☐ 종합 성능 개선 (7-8%)
```

---

## 🎓 **학습 순서**

```
Day 1: Bias 개념 (카페 평가 예시)
Day 2: 영화 추천에서의 Bias
Day 3: 정규화 개념 (스케일 문제)
Day 4: Z-점수 공식
Day 5: Bias + 정규화 결합
Day 6: 실제 코드 구현
Day 7: 성능 측정 및 분석
```

---

**이제 Bias와 정규화를 완벽히 이해했습니다!** 🏆