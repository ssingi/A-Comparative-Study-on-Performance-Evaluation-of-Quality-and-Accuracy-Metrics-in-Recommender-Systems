# Bias와 정규화 빠른 참고 가이드

## 🎯 **핵심 한눈에 보기**

```
Bias (편향):
→ 사용자와 영화의 "고유한 특성" 반영
→ "어떤 사용자는 항상 높게 평가하는 경향"
→ "어떤 영화는 항상 좋은 평가를 받는 경향"
→ 성능 개선: 4-5%

정규화:
→ 모델들의 "스케일 조정"
→ "서로 다른 범위의 예측값을 같게 만들기"
→ "공정한 가중 평균을 위해"
→ 성능 개선: 3%

결합:
→ RMSE: 1.05 → 1.00 (5% 개선)
```

---

## 📚 **Bias 3가지 유형**

### **1️⃣ User Bias (사용자 편향)**

```
정의:
user_bias = 사용자_평균_평점 - 전체_평균_평점

예시:
전체 평균: 3.5점
사용자 A 평균: 4.2점
user_bias[A] = +0.7
→ 사용자 A는 긍정적 (높게 평가)

사용자 B 평균: 2.9점
user_bias[B] = -0.6
→ 사용자 B는 비판적 (낮게 평가)
```

### **2️⃣ Movie Bias (영화 편향)**

```
정의:
movie_bias = 영화_평균_평점 - 전체_평균_평점

예시:
전체 평균: 3.5점
영화 X 평균: 4.5점
movie_bias[X] = +1.0
→ 영화 X는 좋은 영화

영화 Y 평균: 2.0점
movie_bias[Y] = -1.5
→ 영화 Y는 나쁜 영화
```

### **3️⃣ Global Bias (전체 편향)**

```
정의: 전체 데이터셋의 평균 평점

예:
global_bias = 3.5점
→ 모든 예측의 기본값
```

---

## 🔢 **정규화 공식**

### **Z-점수 정규화**

```
공식:
정규화된_값 = (원래_값 - 평균) / 표준편차

단계별:
1. 평균 계산
   mean = (모든 값의 합) / 개수
   
2. 표준편차 계산
   std = √(편차 제곱의 합 / 개수)
   
3. 정규화
   normalized = (값 - mean) / std
```

### **예시**

```
원래 값: [1, 2, 3, 4, 5]
평균: 3
표준편차: √2 = 1.41

정규화 후:
(1-3)/1.41 = -1.41
(2-3)/1.41 = -0.71
(3-3)/1.41 = 0
(4-3)/1.41 = 0.71
(5-3)/1.41 = 1.41

결과: [-1.41, -0.71, 0, 0.71, 1.41]
```

---

## 🔗 **최종 예측 공식**

```python
def predict(user_id, movie_id):
    # 1️⃣ 협업 필터링 (정규화)
    user_vec = 정규화(user_factors[user_id])
    movie_vec = 정규화(movie_factors[movie_id])
    
    latent = np.dot(user_vec, movie_vec)
    
    # 2️⃣ 스케일 복원
    scaled = latent * std_rating
    
    # 3️⃣ Bias 추가
    bias = user_bias[user_id] + movie_bias[movie_id]
    
    # 4️⃣ 최종 예측
    pred = scaled + bias + global_mean
    
    # 5️⃣ 범위 제한
    return np.clip(pred, 1, 5)

예시:
latent = 0.8
scaled = 0.8 × 1.2 = 0.96
bias = 0.7 + 1.0 = 1.7
pred = 0.96 + 1.7 + 3.5 = 6.16 → clip(5.0)
```

---

## 📊 **성능 개선 단계**

```
1단계: 기본 협업 필터링
   RMSE = 1.10
   
2단계: 정규화 추가
   RMSE = 1.05 (-4.5%)
   
3단계: Bias 추가
   RMSE = 1.00 (-4.7%)
   
최종: 1.10 → 1.00 (-9.1%) ✅
```

---

## 🎯 **직관적 비유**

### **Bias의 비유: 심판의 성향**

```
기본 점수 (협업 필터링): 3.5점
+ 심판 A의 성향: +0.5점 (관대)
+ 영화 X의 품질: +1.0점 (좋음)
= 최종: 5.0점

vs

기본 점수: 3.5점
+ 심판 B의 성향: -0.5점 (엄격)
+ 영화 X의 품질: +1.0점 (좋음)
= 최종: 4.0점

→ 같은 영화도 심판에 따라 달라짐!
```

### **정규화의 비유: 환율 변환**

```
모델 A: 100달러 ($) [범위: $0-500]
모델 B: 100,000원 (₩) [범위: ₩0-500,000]

직접 비교: 숫자가 너무 다름

정규화: 둘 다 Z-점수로 변환
모델 A: (100-250)/141 = -1.06
모델 B: (100000-250000)/141214 = -1.06

→ 이제 공정하게 비교 가능!
```

---

## 💡 **언제 Bias가 필요한가?**

```
필요한 경우:
✅ 사용자마다 평가 성향이 다를 때
✅ 일부 아이템이 항상 인기 있을 때
✅ 더 정확한 예측이 필요할 때

예시:
- 영화 평점: 높이 평가하는 사용자 O
- 제품 리뷰: 좋은 제품과 나쁜 제품 명확 O
- 음악 순위: 인기곡의 편향 O
```

---

## 💡 **언제 정규화가 필요한가?**

```
필요한 경우:
✅ 여러 모델을 결합할 때
✅ 모델들의 범위가 다를 때
✅ 공정한 가중치가 필요할 때

예시:
- CF (범위: 1-5) + CB (범위: 3-4)
- 5개 알고리즘 결합
- 정규화 하이브리드
```

---

## 🎓 **학습 순서**

### **Day 1: Bias 개념**
```
☐ 카페 평가 예시 이해
☐ User Bias 의미
☐ Movie Bias 의미
```

### **Day 2: 정규화 개념**
```
☐ 스케일 문제 인식
☐ Z-점수 공식
☐ 정규화 효과
```

### **Day 3: 결합**
```
☐ 최종 공식 이해
☐ 단계별 계산
☐ 성능 개선 확인
```

### **Day 4: 코드 구현**
```
☐ Bias 계산 코드
☐ 정규화 코드
☐ 최종 예측 코드
```

---

## ✅ **체크리스트**

```
Bias 이해:
☐ User Bias 계산법
☐ Movie Bias 계산법
☐ 예측에서의 역할
☐ 성능 개선 (4-5%)

정규화 이해:
☐ Z-점수 공식
☐ 정규화 전후 비교
☐ 스케일 문제 해결
☐ 성능 개선 (3%)

결합 이해:
☐ 최종 공식
☐ 각 요소의 역할
☐ 단계별 계산
☐ 총 성능 개선 (9%)
```

---

## 📚 **공식 요약**

```
User Bias:
b_u = μ_u - μ_global

Movie Bias:
b_i = μ_i - μ_global

Z-점수 정규화:
z = (x - μ) / σ

최종 예측:
ŷ = (ℓ^T_u · ℓ_i × σ) + b_u + b_i + μ

여기서:
ℓ_u: 정규화된 사용자 벡터
ℓ_i: 정규화된 영화 벡터
σ: 평점 표준편차
b_u: 사용자 Bias
b_i: 영화 Bias
μ: 전체 평균
```

---

**이제 Bias와 정규화를 완벽히 이해했습니다!** 🏆