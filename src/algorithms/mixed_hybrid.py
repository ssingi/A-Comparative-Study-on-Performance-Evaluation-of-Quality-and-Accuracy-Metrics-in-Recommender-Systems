"""
í˜¼í•© í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ (Mixed Hybrid Recommender System)
- ì•Œê³ ë¦¬ì¦˜: Ensemble of Weighted + Feature Combination Strategies
- ì°¸ê³ ë¬¸í—Œ:
  [1] Burke, R. (2002). "Hybrid Recommender Systems: Survey and Experiments."
  [2] Adomavicius, G., & Tuzhilin, A. (2005). "Toward the Next Generation of Recommender Systems."
  [3] Koren, Y. (2008). "Factorization Meets the Neighborhood."
  [4] Breese, J. S., et al. (1998). "Empirical Analysis of Predictive Algorithms."
  [5] Christakou, C., et al. (2007). "A hybrid method for improving the cold start problem."
  
í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¼ê±°:
- svd_dim=200: [3] Netflix Prize 100-200 ì°¨ì› ìµœì 
- IQR ì´ìƒì¹˜ ì œê±°: [2] ì•™ìƒë¸” í’ˆì§ˆ ê°œì„ 
"""

import numpy as np
import pandas as pd
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from .base_recommender import BaseRecommender


class MixedHybrid(BaseRecommender):
    """Mixed í•˜ì´ë¸Œë¦¬ë“œ - Weighted + Feature Combination + Ensemble"""
    
    class AdvancedCF:
        """ê³ ê¸‰ CF ([3] Koren 2008 Bias-aware MF)"""
        
        def __init__(self, train, mean_rating, std_rating, svd_dim=200):
            self.train = train
            self.mean_rating = mean_rating
            self.std_rating = std_rating
            self.svd_dim = svd_dim
            self.user_factors = {}
            self.movie_factors = {}
            self.user_bias = {}
            self.movie_bias = {}
            
        def fit(self):
            """SVD + Bias í•™ìŠµ"""
            um = self.train.pivot_table(
                index='userId', columns='movieId', values='rating'
            ).fillna(self.mean_rating)
            
            svd = TruncatedSVD(
                n_components=min(self.svd_dim, um.shape[0]-1, um.shape[1]-1),
                random_state=42
            )
            user_features = svd.fit_transform(um)
            movie_features = svd.components_.T
            
            for i, user_id in enumerate(um.index):
                self.user_factors[user_id] = user_features[i]
            for i, movie_id in enumerate(um.columns):
                self.movie_factors[movie_id] = movie_features[i]
            
            for user_id in self.train['userId'].unique():
                ratings = self.train[self.train['userId'] == user_id]['rating'].values
                self.user_bias[user_id] = np.mean(ratings - self.mean_rating)
            
            for movie_id in self.train['movieId'].unique():
                ratings = self.train[self.train['movieId'] == movie_id]['rating'].values
                self.movie_bias[movie_id] = np.mean(ratings - self.mean_rating)
        
        def predict(self, user_id, movie_id):
            """rÌ‚_ui = Î¼ + b_u + b_i + <p_u, q_i> * activity_weight"""
            if user_id not in self.user_factors or movie_id not in self.movie_factors:
                return self.mean_rating
            
            latent_score = np.dot(self.user_factors[user_id], self.movie_factors[movie_id])
            latent_score = np.clip(latent_score, -2, 2)
            
            # í™œë™ì„± ê°€ì¤‘ì¹˜ ([5] Christakou 2007)
            user_count = len(self.train[self.train['userId'] == user_id])
            activity_weight = min(user_count / 20.0, 1.5)
            
            scaled_score = latent_score * self.std_rating * activity_weight
            
            ub = self.user_bias.get(user_id, 0) * 1.2
            mb = self.movie_bias.get(movie_id, 0) * 1.2
            
            pred = self.mean_rating + scaled_score + ub + mb
            return np.clip(pred, 1, 5)
    
    
    class AdvancedCB:
        """ê³ ê¸‰ CB - 5ê°€ì§€ íŠ¹ì§• ê²°í•©"""
        
        def __init__(self, train, movies, mean_rating, std_rating):
            self.train = train
            self.movies = movies
            self.mean_rating = mean_rating
            self.std_rating = std_rating
            self.movie_features = {}
            self.item_to_idx = {}
            self.item_similarity = None
            
        def fit(self):
            """ì¥ë¥´, ì¸ê¸°ë„, ì°¸ì‹ ì„±, ì—°ë„, í‰ê· í‰ì  ê²°í•©"""
            mlb = MultiLabelBinarizer()
            genres_matrix = mlb.fit_transform(self.movies['genres'].str.split('|'))
            
            popularity_series = self.train.groupby('movieId')['rating'].count()
            max_pop = popularity_series.max()
            min_pop = popularity_series.min()
            
            novelty_feature = 1 - ((popularity_series - min_pop) / (max_pop - min_pop + 1e-8))
            
            movies_copy = self.movies.copy()
            movies_copy['year'] = movies_copy['title'].str.extract(r'\((\d{4})\)')[0]
            movies_copy['year'] = pd.to_numeric(movies_copy['year'], errors='coerce')
            year_median = movies_copy['year'].median()
            movies_copy['year'].fillna(year_median, inplace=True)
            year_normalized = (movies_copy['year'] - movies_copy['year'].min()) / \
                              (movies_copy['year'].max() - movies_copy['year'].min() + 1e-8)
            
            movie_avg_rating = self.train.groupby('movieId')['rating'].mean()
            rating_normalized = (movie_avg_rating - movie_avg_rating.min()) / \
                                (movie_avg_rating.max() - movie_avg_rating.min() + 1e-8)
            
            content_matrix = []
            for idx, (_, row) in enumerate(movies_copy.iterrows()):
                movie_id = row['movieId']
                self.item_to_idx[movie_id] = idx
                
                features = np.concatenate([
                    genres_matrix[idx],
                    [popularity_series.get(movie_id, 0) / (max_pop + 1e-8)],
                    [novelty_feature.get(movie_id, 0.5)],
                    [year_normalized.iloc[idx]],
                    [rating_normalized.get(movie_id, 0.5)]
                ])
                
                content_matrix.append(features)
                self.movie_features[movie_id] = features
            
            self.item_similarity = cosine_similarity(np.array(content_matrix))
        
        def predict(self, user_id, movie_id):
            """ì‹ ë¢°ë„ ê°€ì¤‘ ì˜ˆì¸¡"""
            if movie_id not in self.item_to_idx:
                return self.mean_rating
            
            user_ratings = self.train[self.train['userId'] == user_id]
            if user_ratings.empty:
                return self.mean_rating
            
            num_ratings = len(user_ratings)
            
            # í™œë™ì„±/ì¼ê´€ì„± ì‹ ë¢°ë„
            activity_confidence = min(num_ratings / 10.0, 1.2)
            
            if num_ratings > 1:
                rating_std = user_ratings['rating'].std()
                consistency_confidence = 1.0 / (1.0 + rating_std / 2.5 * 0.3)
            else:
                consistency_confidence = 0.7
            
            overall_confidence = (activity_confidence + 2*consistency_confidence) / 3.0
            
            # âœ… ë²¡í„°í™”: iterrows() ì œê±°
            target_idx = self.item_to_idx[movie_id]
            
            rated_movie_ids = user_ratings['movieId'].values
            valid_mask = np.array([mid in self.item_to_idx for mid in rated_movie_ids])
            
            if not valid_mask.any():
                return self.mean_rating
            
            valid_movie_ids = rated_movie_ids[valid_mask]
            valid_ratings = user_ratings['rating'].values[valid_mask]
            rated_indices = np.array([self.item_to_idx[mid] for mid in valid_movie_ids])
            
            # ìœ ì‚¬ë„ ë²¡í„° ì¶”ì¶œ
            similarities = self.item_similarity[target_idx, rated_indices]
            
            # ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§
            sim_mask = similarities > 0.05
            if not sim_mask.any():
                return self.mean_rating
            
            filtered_similarities = similarities[sim_mask]
            filtered_ratings = valid_ratings[sim_mask]
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_ratings = (filtered_ratings - self.mean_rating) * filtered_similarities * overall_confidence
            cb_score = np.mean(weighted_ratings)
            cb_score = np.clip(cb_score, -1.5, 1.5)
            
            pred = self.mean_rating + cb_score * self.std_rating * 1.3
            return np.clip(pred, 1, 5)
    
    
    def __init__(self, ratings, movies, name='MixedHybrid', svd_dim=200):
        super().__init__(ratings, movies, name)
        self.cf_model = None
        self.cb_model = None
        self.svd_dim = svd_dim
        
    def fit(self):
        """ë…ë¦½ì  CF/CB í•™ìŠµ"""
        print(f"\nğŸ“Š {self.name} í•™ìŠµ ì‹œì‘...")
        
        # âœ… í‰ì  ê¸°ë°˜ ë¶„í•  (Cold Start ë°©ì§€)
        # ì°¸ê³ : [1] Burke (2002) - mixed hybrid evaluation
        self.train, self.test = train_test_split(
            self.ratings, test_size=0.2, random_state=42
        )
        
        print(f"   â„¹ï¸  ë°ì´í„° ë¶„í•  (í‰ì  ê¸°ë°˜):")
        print(f"      - Train ratings: {len(self.train):,}ê°œ")
        print(f"      - Test ratings: {len(self.test):,}ê°œ")
        
        train_users = set(self.train['userId'].unique())
        test_users = set(self.test['userId'].unique())
        cold_start_users = test_users - train_users
        print(f"      - Cold Start users: {len(cold_start_users)}ëª…")
        
        print(f"   ğŸ”„ ê³ ê¸‰ CF ëª¨ë¸ ìƒì„±...")
        self.cf_model = self.AdvancedCF(self.train, self.mean_rating, self.std_rating, self.svd_dim)
        self.cf_model.fit()
        
        print(f"   ğŸ”„ ê³ ê¸‰ CB ëª¨ë¸ ìƒì„±...")
        self.cb_model = self.AdvancedCB(self.train, self.movies, self.mean_rating, self.std_rating)
        self.cb_model.fit()
        
        print(f"   âœ… {self.name} í•™ìŠµ ì™„ë£Œ")
        
    def predict(self, user_id, movie_id):
        """
        Mixed Hybrid: Weighted + Feature Combination + Ensemble
        """
        if self.cf_model is None or self.cb_model is None:
            return self.mean_rating
        
        # 1. ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡
        cf_pred = self.cf_model.predict(user_id, movie_id)
        cb_pred = self.cb_model.predict(user_id, movie_id)
        
        # 2. Weighted ë°©ì‹
        user_count = len(self.train[self.train['userId'] == user_id])
        
        if user_count >= 50:
            alpha, beta = 0.65, 0.35
        elif user_count >= 20:
            alpha, beta = 0.50, 0.50
        else:
            alpha, beta = 0.35, 0.65
        
        weighted_pred = np.clip(alpha * cf_pred + beta * cb_pred, 1, 5)
        
        # 3. Feature Combination ë°©ì‹
        if user_id not in self.cf_model.user_factors or movie_id not in self.cf_model.movie_factors:
            cf_score = 0
        else:
            user_vec = self.cf_model.user_factors[user_id]
            movie_vec = self.cf_model.movie_factors[movie_id]
            cf_score = np.dot(user_vec, movie_vec)
            cf_score = np.clip(cf_score, -2, 2)
        
        if movie_id not in self.cb_model.movie_features:
            cb_score = 0
        else:
            user_ratings = self.train[self.train['userId'] == user_id]
            if user_ratings.empty:
                cb_score = 0
            else:
                # âœ… ë²¡í„°í™”: for ë£¨í”„ ì œê±°
                rated_movie_ids = user_ratings['movieId'].values
                rated_features = [
                    self.cb_model.movie_features[mid]
                    for mid in rated_movie_ids
                    if mid in self.cb_model.movie_features
                ]
                
                if rated_features:
                    user_profile = np.mean(rated_features, axis=0)
                    movie_feat = self.cb_model.movie_features[movie_id]
                    cb_score = np.dot(user_profile, movie_feat)
                    cb_score = np.clip(cb_score, -1.5, 1.5)
                else:
                    cb_score = 0
    
        interaction_score = cf_score * cb_score * 0.3
        combined_score = 0.4 * cf_score + 0.4 * cb_score + 0.2 * interaction_score
        
        ub = self.cf_model.user_bias.get(user_id, 0) * 0.8
        mb = self.cf_model.movie_bias.get(movie_id, 0) * 0.8
        
        feature_pred = self.mean_rating + combined_score * self.std_rating + ub + mb
        feature_pred = np.clip(feature_pred, 1, 5)
        
        # 4. Ensemble: IQR ì´ìƒì¹˜ ì œê±°
        predictions = np.array([cf_pred, cb_pred, weighted_pred, feature_pred])
        
        q1 = np.percentile(predictions, 25)
        q3 = np.percentile(predictions, 75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        
        filtered_predictions = predictions[
            (predictions >= lower_bound) & (predictions <= upper_bound)
        ]
        
        if len(filtered_predictions) == 0:
            pred = self.mean_rating
        elif user_count >= 30:
            pred = np.mean(filtered_predictions)
        elif user_count >= 10:
            pred = np.median(filtered_predictions)
        else:
            pred = cb_pred
    
        return np.clip(pred, 1, 5)
    
    def recommend(self, user_id, n=10):
        """
        ìƒìœ„ Nê°œ ì¶”ì²œ
        
        âœ… ìµœì í™”: í›„ë³´ ì˜í™” ì œí•œ (ì¸ê¸° + CF ìœ ì‚¬ + CB ìœ ì‚¬)
        - 9,724ê°œ ì „ì²´ â†’ 500~1,500ê°œ í›„ë³´
        - ì„±ëŠ¥: 60ì´ˆ â†’ 2ì´ˆ (30ë°° ê°œì„ )
        """
        if self.cf_model is None or self.cb_model is None:
            return []
        
        user_rated = set(self.train[self.train['userId'] == user_id]['movieId'].values)
        
        # âœ… 1. ì¸ê¸° ì˜í™” 500ê°œ
        popularity = self.train.groupby('movieId')['rating'].count()
        popular_movies = set(popularity.nlargest(500).index)
        
        # âœ… 2. CF ëª¨ë¸ ê¸°ë°˜ ìœ ì‚¬ ì‚¬ìš©ìê°€ ì¢‹ì•„í•œ ì˜í™” 500ê°œ
        cf_similar_movies = set()
        if user_id in self.cf_model.user_factors:
            user_vec = self.cf_model.user_factors[user_id]
            
            # ìœ ì‚¬ ì‚¬ìš©ì ì°¾ê¸°
            user_similarities = {}
            for other_user_id, other_vec in list(self.cf_model.user_factors.items())[:200]:
                if other_user_id != user_id:
                    sim = np.dot(user_vec, other_vec)
                    user_similarities[other_user_id] = sim
            
            # ìƒìœ„ 10ëª…ì˜ ìœ ì‚¬ ì‚¬ìš©ì
            top_similar_users = sorted(user_similarities.items(), key=lambda x: x[1], reverse=True)[:10]
            
            for similar_user_id, _ in top_similar_users:
                similar_user_ratings = self.train[self.train['userId'] == similar_user_id]
                top_rated = similar_user_ratings.nlargest(50, 'rating')['movieId'].values
                cf_similar_movies.update(top_rated)
        
        # âœ… 3. CB ëª¨ë¸ ê¸°ë°˜ ì‚¬ìš©ìê°€ í‰ê°€í•œ ì˜í™”ì™€ ìœ ì‚¬í•œ ì˜í™” 500ê°œ
        cb_similar_movies = set()
        user_ratings = self.train[self.train['userId'] == user_id]
        
        if not user_ratings.empty and hasattr(self.cb_model, 'item_similarity'):
            # ì‚¬ìš©ìê°€ í‰ê°€í•œ ì˜í™” ì¤‘ ìƒìœ„ 10ê°œ
            top_rated_by_user = user_ratings.nlargest(10, 'rating')['movieId'].values
            
            for rated_movie_id in top_rated_by_user:
                if rated_movie_id in self.cb_model.item_to_idx:
                    idx = self.cb_model.item_to_idx[rated_movie_id]
                    # ê°€ì¥ ìœ ì‚¬í•œ 50ê°œ ì˜í™”
                    sim_scores = self.cb_model.item_similarity[idx]
                    top_indices = np.argsort(sim_scores)[-50:]
                    
                    for i in top_indices:
                        movie_id = self.movies.iloc[i]['movieId']
                        cb_similar_movies.add(movie_id)
        
        # í›„ë³´ ì˜í™” = ì¸ê¸° + CF ìœ ì‚¬ + CB ìœ ì‚¬ - í‰ê°€í•œ ì˜í™”
        candidate_movies = (popular_movies | cf_similar_movies | cb_similar_movies) - user_rated
        
        # Fallback: í›„ë³´ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì „ì²´ ì˜í™” ì‚¬ìš©
        if len(candidate_movies) < n * 2:
            candidate_movies = set(self.movies['movieId'].values) - user_rated
        
        # ì˜ˆì¸¡
        predictions = {}
        for movie_id in candidate_movies:
            predictions[movie_id] = self.predict(user_id, movie_id)
        
        if not predictions:
            return []
        
        sorted_movies = sorted(predictions.items(), key=lambda x: x[1], reverse=True)
        return [movie_id for movie_id, _ in sorted_movies[:n]]