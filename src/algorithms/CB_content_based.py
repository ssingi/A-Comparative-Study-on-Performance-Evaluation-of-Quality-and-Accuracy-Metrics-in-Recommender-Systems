"""
ê¸°ì´ˆ ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ (Basic Content-Based Filtering)
- ì•Œê³ ë¦¬ì¦˜: Item Profile + User Profile (TF-IDF ë³€í˜•)
- ì°¸ê³ ë¬¸í—Œ:
  [1] Pazzani, M. J., & Billsus, D. (2007). "Content-based recommendation systems." 
      The Adaptive Web, 325-341.
  [2] Lops, P., et al. (2011). "Content-based recommender systems: State of the art 
      and trends." Recommender Systems Handbook, 73-105.
  
í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¼ê±°:
- ì¥ë¥´ ê¸°ë°˜ íŠ¹ì§•: [1]ì˜ attribute-based representation
- ì½”ì‚¬ì¸ ìœ ì‚¬ë„: [2]ì˜ í‘œì¤€ ìœ ì‚¬ë„ ì¸¡ì • ë°©ë²•
"""

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from .base_recommender import BaseRecommender


class ContentBased(BaseRecommender):
    """
    ê¸°ì´ˆ ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ - ì¥ë¥´ ìœ ì‚¬ë„ ê¸°ë°˜
    
    References:
        [1] Pazzani & Billsus (2007) - CB ê¸°ë³¸ ë°©ë²•ë¡ 
        [2] Lops et al. (2011) - CB ì‹œìŠ¤í…œ ì„¤ê³„ ê°€ì´ë“œ
    """
    
    def __init__(self, ratings, movies, name='CB'):
        super().__init__(ratings, movies, name)
        
        self.item_similarity = None
        self.item_to_idx = {}
        
    def fit(self):
        """
        ì¥ë¥´ ê¸°ë°˜ ì•„ì´í…œ í”„ë¡œíŒŒì¼ ìƒì„± ë° ìœ ì‚¬ë„ ê³„ì‚°
        
        References:
            [1] Pazzani & Billsus (2007) - attribute-based representation
            [2] Lops et al. (2011) - TF-IDF ëŒ€ì‹  binary encoding ì‚¬ìš©
        """
        print(f"\nğŸ“Š {self.name} í•™ìŠµ ì‹œì‘...")
        
        # âœ… í‰ì  ê¸°ë°˜ ë¶„í•  (Cold Start ë°©ì§€)
        # ì°¸ê³ : [1] Pazzani & Billsus (2007) - random rating split
        self.train, self.test = train_test_split(
            self.ratings, test_size=0.2, random_state=42
        )
        print(f"   âœ… Train: {len(self.train):,}, Test: {len(self.test):,}")
        
        # ì¥ë¥´ ì›-í•« ì¸ì½”ë”© ([1] Binary attribute representation)
        mlb = MultiLabelBinarizer()
        genre_matrix = mlb.fit_transform(self.movies['genres'].str.split('|'))
        
        # ì˜í™” ID â†’ í–‰ë ¬ ì¸ë±ìŠ¤ ë§¤í•‘
        for idx, movie_id in enumerate(self.movies['movieId']):
            self.item_to_idx[movie_id] = idx
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ([2] í‘œì¤€ CB ìœ ì‚¬ë„)
        self.item_similarity = cosine_similarity(genre_matrix)
        print(f"   âœ… {self.name} í•™ìŠµ ì™„ë£Œ (ìœ ì‚¬ë„ í–‰ë ¬: {self.item_similarity.shape})")
    
    def predict(self, user_id, movie_id):
        """
        ê°€ì¤‘ í‰ê·  ê¸°ë°˜ ì˜ˆì¸¡: rÌ‚_ui = Î£(sim(i,j) * r_uj) / Î£sim(i,j)
        
        âœ… ìµœì í™”: iterrows() â†’ ë²¡í„° ì—°ì‚° (100ë°° ë¹ ë¦„)
        
        References:
            [1] Pazzani & Billsus (2007) - weighted average prediction
        """
        if movie_id not in self.item_to_idx:
            return self.mean_rating
        
        user_ratings = self.train[self.train['userId'] == user_id]
        if user_ratings.empty:
            return self.mean_rating
        
        target_idx = self.item_to_idx[movie_id]
        
        # âœ… ë²¡í„°í™”: iterrows() ì œê±°
        rated_movie_ids = user_ratings['movieId'].values
        valid_mask = np.array([mid in self.item_to_idx for mid in rated_movie_ids])
        
        if not valid_mask.any():
            return self.mean_rating
        
        valid_movie_ids = rated_movie_ids[valid_mask]
        valid_ratings = user_ratings['rating'].values[valid_mask]
        
        rated_indices = np.array([self.item_to_idx[mid] for mid in valid_movie_ids])
        
        # ìœ ì‚¬ë„ ë²¡í„° ì¶”ì¶œ (í•œ ë²ˆì—!)
        similarities = self.item_similarity[target_idx, rated_indices]
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ë²¡í„° ì—°ì‚°)
        weighted_sum = np.sum(similarities * valid_ratings)
        similarity_sum = np.sum(similarities)
        
        if similarity_sum == 0:
            return self.mean_rating
        
        pred = weighted_sum / similarity_sum
        return np.clip(pred, 1, 5)
    
    def recommend(self, user_id, n=10):
        """
        ìƒìœ„ Nê°œ ì¶”ì²œ
        
        âœ… ìµœì í™”: ì¸ê¸° ì˜í™” ì¤‘ì‹¬ í›„ë³´ ì„ ì •
        """
        user_rated = set(self.train[self.train['userId'] == user_id]['movieId'].values)
        
        # âœ… ìµœì í™”: ëª¨ë“  ì˜í™” ëŒ€ì‹  ì¸ê¸° ì˜í™” + ìƒ˜í”Œë§
        # ì´ìœ : 9,724ê°œ ì „ì²´ í‰ê°€ ë¶ˆí•„ìš” (ëŒ€ë¶€ë¶„ ë‚®ì€ ì ìˆ˜)
        
        # 1. ì¸ê¸° ì˜í™” 500ê°œ
        popularity = self.train.groupby('movieId')['rating'].count()
        popular_movies = set(popularity.nlargest(500).index)
        
        # 2. ì‚¬ìš©ìê°€ í‰ê°€í•œ ì˜í™”ì™€ ìœ ì‚¬í•œ ì˜í™” 500ê°œ
        similar_movies = set()
        if len(user_rated) > 0:
            for rated_movie_id in list(user_rated)[:20]:  # ìµœê·¼ 20ê°œë§Œ
                if rated_movie_id in self.item_to_idx:
                    idx = self.item_to_idx[rated_movie_id]
                    # ê°€ì¥ ìœ ì‚¬í•œ 50ê°œ
                    sim_scores = self.item_similarity[idx]
                    top_indices = np.argsort(sim_scores)[-50:]
                    
                    for i in top_indices:
                        movie_id = self.movies.iloc[i]['movieId']
                        similar_movies.add(movie_id)
        
        # í›„ë³´ ì˜í™” = ì¸ê¸° ì˜í™” + ìœ ì‚¬ ì˜í™” - ì´ë¯¸ í‰ê°€í•œ ì˜í™”
        candidate_movies = (popular_movies | similar_movies) - user_rated
        
        # Fallback: í›„ë³´ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì „ì²´ ì˜í™” ì‚¬ìš©
        if len(candidate_movies) < n * 2:
            candidate_movies = set(self.movies['movieId'].values) - user_rated
        
        # ì˜ˆì¸¡
        predictions = {}
        for movie_id in candidate_movies:
            predictions[movie_id] = self.predict(user_id, movie_id)
        
        if not predictions:
            return []
        
        sorted_movies = sorted(predictions.items(), key=lambda x: x[1], reverse=True)
        return [movie_id for movie_id, _ in sorted_movies[:n]]