import numpy as np
import pandas as pd
from tqdm import tqdm
from src.metrics import AdvancedMetrics
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MultiLabelBinarizer


class RecommenderEvaluator:
    """ì¶”ì²œ ì‹œìŠ¤í…œ í‰ê°€ê¸°"""
    
    def __init__(self, model, metrics_class=AdvancedMetrics):
        self.model = model
        self.metrics = metrics_class
        
    def evaluate(self):
        """ëª¨ë¸ í‰ê°€ - ì •í™•ë„, ìˆœìœ„, ë‹¤ì–‘ì„±"""
        print(f"\nğŸ“Š {self.model.name} í‰ê°€ ì¤‘...")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. ì •í™•ë„ í‰ê°€
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        actuals = []
        predictions = []
        
        print("   â³ ì •í™•ë„ ì§€í‘œ ê³„ì‚° ì¤‘...")
        for _, row in tqdm(self.model.test.iterrows(), total=len(self.model.test), desc="   Accuracy"):
            user_id = row['userId']
            movie_id = row['movieId']
            actual = row['rating']
            
            pred = self.model.predict(user_id, movie_id)
            actuals.append(actual)
            predictions.append(pred)
        
        if len(actuals) == 0:
            return self._empty_result()
        
        rmse = self.metrics.rmse(actuals, predictions)
        mae = self.metrics.mae(actuals, predictions)
        
        # ì „ì²´ ë°ì´í„°ì…‹ ê¸°ì¤€ (train + test)
        num_users = self.model.ratings['userId'].nunique()
        num_items = self.model.ratings['movieId'].nunique()
        
        print(f"   ğŸ“Š í¬ì†Œì„± ê³„ì‚°:")
        print(f"      - ì „ì²´ ì‚¬ìš©ì: {num_users:,}ëª…")
        print(f"      - ì „ì²´ ì•„ì´í…œ: {num_items:,}ê°œ")
        print(f"      - í…ŒìŠ¤íŠ¸ í‰ì : {len(actuals):,}ê°œ")
        
        adjusted_rmse = self.metrics.sparsity_aware_rmse(actuals, predictions, num_users, num_items)
        adjusted_mae = self.metrics.sparsity_aware_mae(actuals, predictions, num_users, num_items)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. ìˆœìœ„ í‰ê°€
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("   â³ ìˆœìœ„ ì§€í‘œ ê³„ì‚° ì¤‘...")
        
        # ëœë¤ ìƒ˜í”Œë§
        all_test_users = self.model.test['userId'].unique()
        num_users_total = len(all_test_users)
        
        if num_users_total < 1000:
            num_eval_users = min(100, num_users_total)
        else:
            num_eval_users = min(300, num_users_total)
        
        np.random.seed(42)
        test_users = np.random.choice(all_test_users, size=num_eval_users, replace=False)
        
        print(f"   â„¹ï¸  í‰ê°€ ëŒ€ìƒ: {num_eval_users}ëª… (ì „ì²´ {num_users_total:,}ëª… ì¤‘, ëœë¤ ìƒ˜í”Œ)")
        
        # âœ… ìˆ˜ì •: ìˆœìœ„ ì§€í‘œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        precision_scores = []
        recall_scores = []
        f1_scores = []
        ndcg_scores = []
        map_scores = []
        mrr_scores = []
        
        all_recommendations = []
        
        valid_ranking_count = 0
        recommendation_failures = 0
        no_relevant_items = 0
        
        for user_id in tqdm(test_users, desc="   Ranking"):
            # ì¶”ì²œ ìƒì„±
            recommended = self.model.recommend(user_id, n=10)
            
            if len(recommended) == 0:
                recommendation_failures += 1
                continue
            
            # ê´€ë ¨ í•­ëª© (í‰ì  4 ì´ìƒ)
            user_test = self.model.test[self.model.test['userId'] == user_id]
            relevant = user_test[user_test['rating'] >= 4]['movieId'].values.tolist()
            
            if len(relevant) == 0:
                no_relevant_items += 1
                continue
            
            # ìœ íš¨í•œ í‰ê°€
            valid_ranking_count += 1
            
            # âœ… ìˆ˜ì •: ê´€ë ¨ë„ ë²¡í„° ê³„ì‚°
            relevance = []
            for movie_id in recommended:
                if movie_id in user_test['movieId'].values:
                    actual_rating = user_test[user_test['movieId'] == movie_id]['rating'].values[0]
                    relevance.append(1 if actual_rating >= 4 else 0)
                else:
                    relevance.append(0)
            
            # âœ… ìˆ˜ì •: ìˆœìœ„ ì§€í‘œ ê³„ì‚° ë° ì €ì¥
            precision_scores.append(self.metrics.precision_at_k(recommended, relevant, k=10))
            recall_scores.append(self.metrics.recall_at_k(recommended, relevant, k=10))
            f1_scores.append(self.metrics.f1_at_k(recommended, relevant, k=10))
            ndcg_scores.append(self.metrics.ndcg_at_k(relevance, k=10))
            map_scores.append(self.metrics.map_at_k(recommended, relevant, k=10))
            mrr_scores.append(self.metrics.mrr_at_k(recommended, relevant, k=10))
            
            # ë‹¤ì–‘ì„± ê³„ì‚°ìš©
            all_recommendations.extend(recommended)
        
        # í†µê³„ ì¶œë ¥
        print(f"   â„¹ï¸  ìˆœìœ„ í‰ê°€:")
        print(f"      - ì´ í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì: {len(test_users)}ëª…")
        print(f"      - ìœ íš¨í•œ í‰ê°€: {valid_ranking_count}ëª…")
        print(f"      - ì¶”ì²œ ì‹¤íŒ¨: {recommendation_failures}ëª…")
        print(f"      - Relevant í•­ëª© ì—†ìŒ: {no_relevant_items}ëª… (í‰ì  4 ì´ìƒ ì—†ìŒ)")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 3. ë‹¤ì–‘ì„± í‰ê°€
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("   â³ ë‹¤ì–‘ì„± ì§€í‘œ ê³„ì‚° ì¤‘...")
        
        diversity_users = 0
        for user_id in tqdm(test_users, desc="   Diversity"):
            recommended = self.model.recommend(user_id, n=10)
            if len(recommended) > 0:
                diversity_users += 1
        
        print(f"   â„¹ï¸  ë‹¤ì–‘ì„± í‰ê°€: {diversity_users}/{len(test_users)} ì‚¬ìš©ì")
        
        if len(all_recommendations) == 0:
            return self._empty_result()
        
        # ì˜í™” íŠ¹ì§• ì¶”ì¶œ
        movie_features = self._extract_movie_features()
        
        diversity = self.metrics.diversity(all_recommendations, movie_features)
        
        total_items_count = len(self.model.movies)
        coverage = self.metrics.coverage(all_recommendations, total_items_count)
        
        popularity = self.model.train.groupby('movieId')['rating'].count().to_dict()
        novelty = self.metrics.novelty(all_recommendations, popularity)
        popularity_bias = self.metrics.popularity_bias(all_recommendations, popularity)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 4. ê²°ê³¼ ë°˜í™˜
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        result = {
            'Model': self.model.name,
            'RMSE': rmse,
            'MAE': mae,
            'Adjusted_RMSE': adjusted_rmse,
            'Adjusted_MAE': adjusted_mae,
            'Precision@10': np.mean(precision_scores) if precision_scores else 0.0,
            'Recall@10': np.mean(recall_scores) if recall_scores else 0.0,
            'F1@10': np.mean(f1_scores) if f1_scores else 0.0,
            'NDCG@10': np.mean(ndcg_scores) if ndcg_scores else 0.0,
            'MAP@10': np.mean(map_scores) if map_scores else 0.0,
            'MRR@10': np.mean(mrr_scores) if mrr_scores else 0.0,
            'Diversity': diversity,
            'Coverage': coverage,
            'Novelty': novelty,
            'PopularityBias': popularity_bias
        }
        
        print(f"   âœ… {self.model.name} í‰ê°€ ì™„ë£Œ")
        return result
    
    def _extract_movie_features(self):
        """ì˜í™” íŠ¹ì§• ì¶”ì¶œ"""
        from sklearn.preprocessing import MultiLabelBinarizer
        
        mlb = MultiLabelBinarizer()
        genres_matrix = mlb.fit_transform(self.model.movies['genres'].str.split('|'))
        
        popularity_series = self.model.train.groupby('movieId')['rating'].count()
        max_pop = popularity_series.max() if len(popularity_series) > 0 else 1.0
        
        movie_features = {}
        for idx, (_, row) in enumerate(self.model.movies.iterrows()):
            movie_id = row['movieId']
            
            genre_vec = genres_matrix[idx]
            pop_score = popularity_series.get(movie_id, 0) / (max_pop + 1e-8)
            
            feature_vec = np.concatenate([genre_vec, [pop_score]])
            movie_features[movie_id] = feature_vec
        
        return movie_features
    
    def _empty_result(self):
        """ë¹ˆ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
        return {
            'Model': self.model.name,
            'RMSE': 0.0,
            'MAE': 0.0,
            'Adjusted_RMSE': 0.0,
            'Adjusted_MAE': 0.0,
            'Precision@10': 0.0,
            'Recall@10': 0.0,
            'F1@10': 0.0,
            'NDCG@10': 0.0,
            'MAP@10': 0.0,
            'MRR@10': 0.0,
            'Diversity': 0.0,
            'Coverage': 0.0,
            'Novelty': 0.0,
            'PopularityBias': 0.0
        }